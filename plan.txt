The path to completion:

Get VE-State to run as a multi-stage model with the WSDOT Scenarios.

Get the scenario setup working, using addstage and building directories (and InputPath) as
needed.

Basic scenario operation:
  Scenario configuration (inline via addstage, written into StageDir/visioneval.cnf, possibly
    saving the settings back out into visioneval.cnf after setting them up dynamically)
  Key Scenario elements:
    StartFrom stage (possibly free-standing) - sets DatastorePath, base InputPath
    InputPath (from StageDir or StageDir/InputDir)
  Verify that InputPath is cumulative:
    Add StageDir (if present), StageDir/InputDir (if present)
    Push all of that ahead of the StartFrom InputPath
    InputPath may be a vector in the stage (as when constructing a scenario from categories and
     levels).
  Notion of ScenarioRoot (where to look for Scenario elements)
  A: compose scenario categories and levels
     This construction happens within a copy of the BaseModel - we build multiple stages. Identify
     the model into which to inject stages. Come up with a name scheme for Stage (StageDir). Build
     the InputPath/configuration - can be inline in Model/ModelStages. Don't need to build StageDir
     for input (keep configuration in copy of BaseModel); use StageDir for output; put
     configuration in Model/ModelStages.
       1. ScenarioDir is used when processing category/level spreadsheet to find input folders
          that are then placed into the constructed stage configurations. We don't want to copy
          the input folders. So perhaps we build a series of configurations for each stage and
          we just end up with "A3B1C1D2.cnf" in the ScenarioDir.
       2. ScenarioDir defaults "scenarios" relative to ModelDir, but can be absolute
       2. StartFrom stage may be supplied; null modification (no additional input path) will
          just reproduce that stage - but perhaps we want to use it "as-is" so if InputPath
          for a stage is empty, it is not generated (with a warning).
     Workflow:
       $scenarios()
         # Return a VEModelScenario object from Model's "Scenarios" key
         # Could be proactive: if no Scenarios key and default Dir exists, open visioneval.cnf from
         #   there and build a "Scenarios" key in the model
         # If no key available, report no scenarios defined
         # Otherwise parse key and return a VEModelScenario object
       $scenarios(
          Dir=model$settings("ScenarioDir"),
          StartFrom=<last Reportable stage, or NULL>,
          Create=FALSE
          )
         # If Create==TRUE, create ScenarioDir=Dir (if not present)
         #   If directory was not present, remove Model Scenarios key
         #   Then set Create=FALSE
         # If Create==FALSE 
         #   Create Model Scenarios key if not present
         #   If ScenarioDir contains visioneval.cnf use that to (re-)populate Model's "Scenarios" key
         # Probably also want to save in the ScenarioDir visioneval.cnf as we create them so we can
         #   recreate the scenarios:
         #     ScenarioDir (hosting categories, inputs)
         #     StartFrom (stage existing in model; over-written from $scenarios argument)
         #     ScenarioStages (added later by VEModelScenario$buildstages
         # Does not otherwise alter what is in ScenarioDir - just works on the Model

       Change ModelStage processing so the scenario stages are sought if the Scenarios
         key exists in the Model configuration. Those are appended after the last
         regular ModelStage (note that the scenarios are automatically considered
         Reportable, and we don't alter Reportable for any "StartFrom" stage)

       The $scenario function returns a VEModelScenario object that we can manipulate.
         # Has Model object reference, ScenarioDir, StartFrom, ScenarioParam_ls
         #   (ScenarioParam_ls load/saves to ScenarioDir/visioneval.cnf)
       Functions for VEModelScenario:
         # Keep track of whether VEModelScenario is unsaved and save it
         $save()
           # rewrites ScenarioParam_ls into ScenarioDir/visioneval.cnf
         $inputs(Filename="CategoryInputs.csv")
           # If scenario StartFrom not defined, use last Reportable stage
           # return a data.frame of category, input files from StartFrom stage
           # if Filename provided, create that file (basename only) within ScenarioDir
           # if Filename exists, read it and return the data.frame, otherwise create it
           # Category is an empty string unless manually added to Filename
           $ Save Filename as CategoryInputs in ScenarioParam_ls
         $categories(Category_df,Filename,inputs=FALSE)
           # Category_df has Category/Description
           # Filename to open if Category_df not provided or to save if Category_df provided
           # If inputs==TRUE, look up Category in $inputs and add a Files column
           #   Order data.frame by Category, InputFile
           #   Adds Input to columns, and one row per input with Category/Description duplicated
           # Returns Category_df (with optional Input column)
           # Record Category_df in VEModelScenario and push CategoryFile into Scenario
           #   visioneval.cnf
           # If no parameters, return Category_df from within VEModelScenario, possibly
           #   opening CategoryFile from within ScenarioParam_ls, if the file exists.
         $levels(Levels_df,Filename)
           # Levels_df has Category/Level/Description
           # Filename to open if Levels_df not provided or to save if Levels_df provided
           # If inputs==TRUE, look up Category in $inputs and return files for Category
           #   Adds Input to columns, and one row per input with
           #    Category/CategoryDescription/Level/LevelDescription duplicated
           #   Also add Exists column to see if file exists in CategoryLevel subdirectory
           # Returns Levels_df (with optional Inputs/Exists columns)
           # Record Levels_df in VEModelScenario and push LevelsFile into Model config
           # If no parameters, return Levels_df from within VEModelScenario, possibly opening
           #   LevelsFile from within Model, if it exists
         $initfiles()
           # Do nothing (Warn) if Categories and Levels not set
           # Verify that a subdirectory is available for each CategoryLevel; create as needed
           # Note that this will not (initially) clean up any CategoryLevel subdirectories for
           #   Category or Level which was removed.
           # If not all Category files exist in the CategoryLevel subdirectory, copy missing ones
           #   from the StartFrom stage
           # NOTE: never delete any input files
           # Warn on any Category with no input files defined
         $buildstages(UseCategories=TRUE, Implicit=TRUE, Reset=FALSE)
           # Will load manual stages if Categories and Levels not set up
           # Process CategoryLevel from Model (permutations) if they are fully defined
           # Warn if they are not and roll over to Implicit, if requested
           # If Reset is TRUE, ignore any existing Scenarios/ModelStages in Model and rebuild
           #   Otherwise warn that stages are already built (and use Reset to rebuild)
           # Build ModelStages (goes into Scenarios section)
           # If Categories and Levels not fully defined and Implicit==TRUE, build ModelStages
           #   from explicit subdirectories of ScenarioDir (see manual stages below)
           # The result needs to be a ModelStages structure placed in the Model's Scenarios key
           # The ModelStages shold be culled for "runnable" (but Reportable should always be TRUE
           #   on the ones that remain).
           # Should end up defining:
           #   Name (of stage)
           #   Dir (compound name for stage, for ResultsDir)
           #   Scenario (==Stage Name; may not need if Name propagates to Dir)
           #   Description (Category + Level Descriptions): could end up REALLY long...
           #   InputPath (compounded as path to CategoryLevel subdirectories relative to
           #     ScenarioDir) - should normalize when Scenario stages are loaded.
           #   Reportable (always TRUE)
           #   Do we need any other configuration for the stage? More can just end up
           #   as extras in the Scenarios/ModelStages entry - we don't do individual configs.

First try:
Build a process controller for the model stages. To run the model, we create a queue of future
objects for each stage, with each one running a stage. +We can't start a stage until its "StartFrom"
is complete. So we'll group the stages by "StartFrom". We'll make a future running the stage into
each stage in the Group (we can start everybody in the group all at once); then we'll loop over
the group until all the elements are resolved.

Scan the list of stages to make groups:
  1. All stages, in order, with no "StartFrom"
  2. For each stage G in Group 1:
     All stages that StartFrom=="G"
  3. For each Group created in 2, do the same operation on any remaining ungrouped stages

The Groups are always run sequentially.
The individual stages in each group can run in parallel.
  If free workers > 0 add a future, otherwise poll ealier futures for resolved
    If resolved, then
      get the future's value (which should be the RunStatus) and put it in the Stage
      start the next future
    Otherwise, wait a second

The process runner can generate an offline status file as the processes it is polling finish and
new ones get started. That status file, which belongs to the model that the process runner is
processing, gets re-read when we ask for process status. That would ideally be a transactional
database... process runner does a polling loop on its processes to start N number of them, then
polls for finish and queue the next. It will also poll for presence of an updated request file. We
could just create a file system message queue (request/response) that uses files with standard
names and timestamps. So when we start running a model, we create the message queue directory (temp
directory) and send it to the process runner as a parameter. The process runner will poll for a
new file (written into under a temporary name, then renamed as an "almost atomic" operation) and
gather data to write into the response file (same timestamp as the request) - write the file under
a temp name, then rename it as an "almost atomic" operation. So we write the request, then go into
a loop waiting (up to a timeout) for the response file from the process runner.

Don't forget to manage the writeLog so when we do the run, the logging only goes to a file (not
the console).

Poll the r_process object for the run status. The results after the process is over (function
returns or fails) are backloaded into the model stage.

Need a simplified process status report (table) showing the Run Status for each stage, including
the low-level process status (so they can be cleaned up). Simple run management functions
(start/restart, stop, purge).

Create a "Waiting" status that is set into all the ModelStages for all the stages the model will
run. The ModelStages are grouped by their StartFrom (no StartFrom first). Then the process runner
will keep NUM_CORES processes running. When a process finishes, the next waiting in its group is set
in motion. When the group has all been set in motion and a core becomes free, the first waiting in
the next group is started. If any stage fails, the process runner does not add any additional
stages; all running ones will be allowed to complete/fail. Problems can be fixed, and a "continue"
run can be launched, which will set all incomplete stages to "Waiting" then start running them.

The process management does imply that we should have a single process runner that lives outside any
particular model. The model furnishes the list of stages to run and then calls the global
(singleton) process runner. That won't stop us from starting R twice, but it will let us trap
problems from having different models (or the same one!) running at the same time.

One way to manage that is not to allow any other model to run() until there are no more running
processes. Doing "running" will check if any model is running (it can be accessed via a model object
but also via a class function (VEModel$runner, for the process runner). That function will take a
command line option, and if none provided will show the running stages. We can ask for "waiting",
"complete", "failed", "running", or "paused" or some vector subset of those. We can also give a verb
plus PID to act on a particular process ("kill", "pause", "resume"). Default display: show
"complete", then "failed", then "waiting", then "running", then "paused". That is accomplished by
posing questions to the background process, which itself is in a loop to poll the processes.

Since the runner needs to be polling regularly (or using "future") to monitor the status of processes.

Organize Stages in the order of their StartFrom stage (no StartFrom are first). Queue the first group.
Then when a stage finishes, see if there is a group with 

Keep stages waiting if their StartFrom is not "Run Complete", and when a stage finishes, find any
later stages that StartFrom it and set all of those running.
  Run up to "max_child" processes - a runtime configuration item in VEModel, defaulting to 4.
  When a stage finishes, see if there are more queued for the current StartFrom

We can efficiently run the stages like this: Classify them as those that start from scratch and
those that StartFrom. Note that if there is a LoadModel/LoadStage directive, that is treated like a
"StartFrom", and we look back to see if that model/stage is available and has been run, then copy it
into the first model stage. All of that should happen prior to starting parallel processing (though
we could run the LoadModel if it is not RunComplete).
  1. Collect the "free" stages and run them in parallel (probably there will only be one).
  3. When ANY stage is complete, look down the list of stages for those that StartFrom the completed
     one's name. Set all those running.
  2. Move to the first "StartFrom" stage, and find all the other stages that start from the same
  place; those can run in parallel
  3.

Experiment with running a stage using 'callr': what do we need to construct in the separate R process
environment: all data/configuration elements present in the same location (all relative to ModelDir).
The RunParam_ls for the stage should be complete - build it and pass it to the child process.

Absorb Dan et al's scripts for extracting metrics...

Create the model visualizer (dump detailed structures to a JSON file, and then launch a static page
to navigate it). Visualizer should include the scripts, the configurations (including grayed-in defaults),
the module inputs and outputs. That can be a warmup for the full scenario viewer.

Create an option to the addstage function to make a stage in the file system (sub-directory within
the ModelDir), containing an (optional) Scripts directory, a visioneval.cnf (with the extras, and an
Inputs directory)
  - Create=TRUE (by default): look for/create StageDir if any Scripts/Inputs/Config are specified;
    can be forced to FALSE to leave everything only in memory. If we don't specific at least one of
    Scripts/Inputs/Config, the stage will take those from the Model - still need the Scenario specifiers
    like Scenario, Description.
  - Scripts=TRUE (by default): look for/create ScriptsDir in StageDir
  - Inputs=TRUE (by default): look for/create InputDir in StageDir; NA is like TRUE in forcing Create but does not
    make an InputDir sub-directory (expect just to drop the inputs into StageDir)
  - Config=TRUE (or filename): dump stage-specific parameters into filename/visioneval.cnf (otherwise leave
    them only in the ModelStage structure saved into the model). If they get saved to a file, remove
    the extras from the ModelStage, leaving only the Name, Dir, Config, Reportable etc. basic parameters.

If inputs have been developed elsewhere, option to provide a string of file paths (absolute) that
will be copied into the scenario stage directory.

So the VEScenario operation should go like this:
  - Identify a Base Model (an open VEModel) and copy it to the Scenario Model
  - Identify the ScenarioConfig configuration files describing the scenarios (see VEScenario)
  - Identify (or create) the "StartFrom" stage that is the basis for all the scenarios (e.g. "Future Year")
  - Generate a (possibly long) sequence of Reportable model stages that get written back out to the
    Scenario Model Copy's visioneval.cnf by iterating through the Scenario configurations. This uses
    "addstage" and will create directories with visioneval.cnf and inputs for each combined scenario.
  - Extend that mechanism to handle manually constructed scenarios (see Eric's scripts) - that's a tweak
    to the configuration file.
  - Using this scenario function, the stages are written to the model's config (just Name and Dir),
    but we also create directories with visioneval.cnf plus inputs. Those directories will be mirrored
    in results.

The "addstage" function should default to rewriting the ModelStages structure in the model's
visioneval.cnf. Could just do it in memory (leaving the residue in the ModelState_ls/RunParam_ls
results structure).

Add a metadata element ("Notes" structure) to visioneval.cnf that just contains an array of strings.
Later useful in the model inspector.

Set up scenarios using addstage function:
  1. Add a scenario to the model's runtime
     - Start From (base scenario)
  2. Rewrite the model stages description to the Model/Stage configuration (save it back out)
     A. Model gets Stage Configuration (stage does not get explicit configuration)
     B. Stage Configuration:
        - Path may not be set (it includes "Inputs" and "Scripts" if those vary for the scenario)
        - Config is not set in this case (but could be)
        - StartFrom (base scenario that other scenarios modify)
        - Dir (name of output subfolder for this scenario in ResultsDir)
        - Name
     C. Extra configuration parameters (also placed in ModelStages)
        - InputPath (one or more directories with scenario inputs)
        - Description
        - Reportable (defaults to TRUE)

Update the scenario viewer to be fully table driven.

If we open a VisionEval result set, we want to be able to patch in missing pieces if the run_model.R
was run using "source" on a script that includes initialize model. Can we open a model that was
"source'd", or must it have run in VE? Probably the latter, though it might be interesting to see if
openModel/VEModel$new can inject the missing information into the ModelState (run status, etc) by
reading the model and inspecting the results. Or we could suspend certain types of error checking if
the result artifacts are present (i.e. assume that Run Status is complete if the directory contains
what is needed).

Make sure queries and results give better errors if deployed on a model that has not yet been run.

Do a walkthrough for staged models (with scenarios, going all the way through to queries).

Check on query geography adjustment - can that really work?
Check on using Bzones as the geography level.
Check on doing all geographies (or a subset) rather than a single GeoValue

Does the H5 storage format still work?

Extract should work on a flat Datastore - I think we're doing that by flattenig the DatastoreListing.

Restructure Query output to use sub-folders.

Automate the debug dump. If we have a model that has crashed in a certain stage, we should be
able to open it, then do a crash exploration.

Get RunScript specified and working (to go with RunModule).

VEModel workflow:

Do ALL the tests (re-run every single model) and save the log results in a file for scrutiny.

In VEQuery, look at Brian's Bzone adjustments and allow Bzones to be a summary unit.
Let the Geography value be a list for summarizing.

Longer term: consider give a class to the ModelState_ls as well, so printing it
  will just show its names (and perhaps a summary of each item - the text itself
  if it's short, or a summary of long, multi-element items)

It would be great to develop a "debug dump" tool:
  Copy and zip the full model plus ResultsDir into a temp dir
  Zip the temp dir
  Send to some large file recipient address (could use SLFTS to receive)
    These outputs can get truly huge!
  Then there's a setup for a new model using the provided one:
    Copy the crashed model to a new model directory
    Adjust run_model.R to pick up where it crashed (from Log)
    Use LoadModel/LoadStage to identify model and stage for LoadDatastore
      Important to set LoadStage since it may have crashed in an earlier stage
      that was not reportable. The default is the previous model's final stage.
    Rewrite the run_model.R and the visioneval.cnf

Here's a slightly more elaborate approach
Steps:
  0. Open a model
  1. User supplies names of packages and modules
     User supplies name for the resulting model slice (default 'PostMortem')
  2. Default is last package/module listed in the log file listed before the [Error]
     Option to bundle an entire runnable model (plus the Datastore)
  4. Pull out just the group/table/name for that listed module(s)'s "Get" specifications.
  5. Make a new Datastore with DatastoreListing.Rda in a PostMortem directory
     That should result from flattening the Datastore (but filtering its contents by
     Group/Table/Name). Can use the Datastore copy operation but with a specific
     list of Datastore elements (new implementation).
  6. Include the ModelState_ls and the log file; include the "defs" directory and an
     inputs directory that only includes the "Inp" files for the package/modules.

On the other side, have an openPostMortem function that will build a mini-model to run
the module that may have crashed.
  0. Expand out into a PostMortem model.
  1. Create a run_model.R and a visioneval.cnf (dump the ModelState_ls$RunParam_ls)
     Make sure the directories map into the PostMortem model... (adjust many RunParam_ls
     entries like ParamPath, etc.).
  2. Put the inputs and defs directories in place.
  3. Do LoadDatastore=TRUE and set the path to the PostMortem Datastore directory
     Does the Datastore name have to include getRunParameter("DatastoreName")?
  4. Should have a runnable model with one stage that loads the PostMortem datastore
     and runs just the modules that were used to generate the PostMortem.

PostMortem need not be run on a failed model - it can be used to create a testbed for
any module, even if one that is working correctly.

Likewise with queries: resutsdir/outputs/query-timestamp/{queryspec,scenarios (results paths), output table}

Review Arash's scenario manager plus Eric Englin's additions.

#) Make several copies of the same base model with different years (only future) and different
   Model Name and Scenario Name.  Then check that we get good output from:
     List of model names
     List of model results
     List of model result directories
#) Add some specifications with the "By" option (income analysis, also by MArea or Azone, and by
   both. See how that shows up in the data.frame of results
#) Test running the same query set at different geographies
#) Think about the API for looking into a "scenario" root directory (where we might probe into
   sub-folders looking for VEResults based on existence of Datastore and ModelState.rda...).
   Eventually all that gets easier with the new VEScenario approach - we'll be able to require
   everything to have the same BaseModel, and a single master ResultsDir for the scenarios.

#) Explore running models in a separate space
   a) Launch an R process that we pre-load with objects from the current process
      Need visioneval, VEModel (full .libPaths); set working directory (ve.runtime)
      and then load/run a particular model. Need to make sure that the whole search
      path is properly constructed (including local environments) and that the
      runtime environment stuff stays loaded. What's the least we could do in a child
      process to make a model run (load VEModel, open the model, run it). Then when
      the process is done, reload the model state (as we currently do) in the front-end
      R session.
#) Get the scenario stuff integrated - very simple set of scenarios
   a) That will be the moment to change the Datastore access, which will need some
      careful thinking about how to initialize (bomb the model initialization if
      the base model has not been run, or should we recursively run the base model?).
      Specify the base model as a VEModel, or just by locating its ResultsDir (both).
   b) Future scenarios just run individual years, not the BaseYear. If there is no BaseModel
      run the BaseYear. Otherwise just run the other explicit years. Models with a BaseModel
      can but should not run the BaseYear.
   c) The key for the scenarios is not to run the BaseYear, which we can easily do just by
      leaving it out of Years.
   d) The BaseModel stuff initially should also encompass the RunScript, and load the
      BaseModel run parameters (so the derived model doesn't need to have any configuration
      other than the InputPath and ResultsDir). If we define Scenarios within the BaseModel
      then we'll just need a set of InputPath elements for each scenario category/level
      that we concatenate into a full set for the Scenario. So the tree could look like:
      /Base-Model
        /inputs
        /defs
        /results
        /queries
        /Scenarios
          /ScenarioName
            ... config files at the root
            ... config files specify category/level plus names
            ... config files also specify the .VEqry that will be applied to generate
                a comparative table of all the scenario results.
            /inputs
              /Category-Level folders with the input files
            /results
              /One subfolder for each permutation of category/level
              /outputs (for queries that run across the full set of results)
   e) Then do the visualizer base on what appears in the 

** Inspector

The inspectModel function should do a very simple interaction:
  1) We launch the HTML viewer, and point it at the page for the kind
     of thing being inspected
  2) Should be able to walk up or down the ladder
  3) Pass to Javascript should be a "Model" or "Collection" (Backbone concepts) with
     a particular name/processing type
  4) Stuff is available

Things we want to inspect:
  1) Settings
    a) Defaults
    b) Global (after ve.runtime)
  2) Models (model directory)
    a) List all models and inspect one
  3) Queries (query directory)
    a) List all queries (root) and inspect one
  4) One Model
    a) List all model stages and inspect one
    b) List all queries for Model (global, model-specific) and inspect one
    c) List Identifier, paths to all result sets for the Model
  5) One Model Stage
    a) Settings
    b) Input Directory (and files present)
    c) Param Dir (and files present)
    d) run_model.R script (raw text)
    e) initializeModel parameters (LoadDatastore)
    f) AllSpecs_ls (ordered sequence of Package/Module/Specs)
        Show Packages
        Within Packages expand to show Modules
        Within Modules expand to show Input, Get, Set specs
        Within a spec
          If Input, show InputDir, File, Group, Table
            Within InputDir,File show Fields, Units, Description
              Expand optionally to remining non-NA spec elements
          If Get/Set
            Show Group/Table
              Within Group, Table show Name, Units, Description
                Expand optionally to remaining non-NA spec elements
  6) One Query
    a) List of Query Specifications (names) and expression, pick one
    b) One Query Specification
       Full list of defined specification elements
